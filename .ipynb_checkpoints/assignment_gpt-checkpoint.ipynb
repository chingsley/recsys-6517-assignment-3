{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ww6md8Na28oz"
      },
      "source": [
        "# Assignment-3: CSCI 6517 Recommender System\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "L5TEL9_hKIf5"
      },
      "source": [
        "## 0. Initializing and Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-25T03:19:22.694673Z",
          "start_time": "2024-06-25T03:19:22.504263Z"
        },
        "collapsed": true,
        "id": "G8wW_Y91KIf8"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "yCS8r50VKIf9"
      },
      "source": [
        "## Q1. Data Processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKI92YvDKIf_"
      },
      "outputs": [],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9m5CO3ltKIf_"
      },
      "outputs": [],
      "source": [
        "# read order_products__train.csv from Data folder\n",
        "order_products_train = pd.read_csv('order_products__train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "Ol9qYhWeKIf_",
        "outputId": "f7059324-e2b9-4545-c6c3-94db00a75c79"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "order_products_train"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0ddc72fb-b3e5-493a-a19d-e7a85351f4a7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>order_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>add_to_cart_order</th>\n",
              "      <th>reordered</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>49302</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>11109</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>10246</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>49683</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>43633</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>13176</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>47209</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>22035</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>36</td>\n",
              "      <td>39612</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>36</td>\n",
              "      <td>19660</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>36</td>\n",
              "      <td>49235</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>36</td>\n",
              "      <td>43086</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>36</td>\n",
              "      <td>46620</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>36</td>\n",
              "      <td>34497</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>36</td>\n",
              "      <td>48679</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>36</td>\n",
              "      <td>46979</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>38</td>\n",
              "      <td>11913</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>38</td>\n",
              "      <td>18159</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>38</td>\n",
              "      <td>4461</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>38</td>\n",
              "      <td>21616</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ddc72fb-b3e5-493a-a19d-e7a85351f4a7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0ddc72fb-b3e5-493a-a19d-e7a85351f4a7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0ddc72fb-b3e5-493a-a19d-e7a85351f4a7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5032d320-8972-43c5-8ba4-1c27da0c87af\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5032d320-8972-43c5-8ba4-1c27da0c87af')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5032d320-8972-43c5-8ba4-1c27da0c87af button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    order_id  product_id  add_to_cart_order  reordered\n",
              "0          1       49302                  1          1\n",
              "1          1       11109                  2          1\n",
              "2          1       10246                  3          0\n",
              "3          1       49683                  4          0\n",
              "4          1       43633                  5          1\n",
              "5          1       13176                  6          0\n",
              "6          1       47209                  7          0\n",
              "7          1       22035                  8          1\n",
              "8         36       39612                  1          0\n",
              "9         36       19660                  2          1\n",
              "10        36       49235                  3          0\n",
              "11        36       43086                  4          1\n",
              "12        36       46620                  5          1\n",
              "13        36       34497                  6          1\n",
              "14        36       48679                  7          1\n",
              "15        36       46979                  8          1\n",
              "16        38       11913                  1          0\n",
              "17        38       18159                  2          0\n",
              "18        38        4461                  3          0\n",
              "19        38       21616                  4          1"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "order_products_train.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "2dwxekUlKIgA"
      },
      "source": [
        "### Q1.a Split data into holdout and cold start set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0WKrGOOKIgB",
        "outputId": "e264ad0a-818c-4a4f-87eb-9e4d413a7797"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1384617, 4)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "order_products_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiQK776UdUd0"
      },
      "outputs": [],
      "source": [
        "order_groups = order_products_train.groupby('order_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55BO8M6mKIgB",
        "outputId": "7a50a103-7c4d-4fd9-c037-dc479ce6d36f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "131209"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(order_groups)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaQPRpKeKIgB"
      },
      "outputs": [],
      "source": [
        "# Extracting the unique group keys\n",
        "group_keys = order_groups.groups.keys()\n",
        "\n",
        "\n",
        "holdout_groups, coldstart_groups = train_test_split(list(group_keys),\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Creating holdout and cold start dataframes\n",
        "holdout = pd.concat([group_data for group_key, group_data in order_groups if group_key in holdout_groups])\n",
        "coldstart = pd.concat([group_data for group_key, group_data in order_groups if group_key in coldstart_groups])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHTjopOrKIgC"
      },
      "outputs": [],
      "source": [
        "print('Number of groups in holdout groups: ', len(holdout_groups))\n",
        "print('Number of groups in cold start groups: ', len(coldstart_groups))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykb4DUg5dUd1"
      },
      "outputs": [],
      "source": [
        "holdout.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRGxiS2YdUd1"
      },
      "source": [
        "### Q1.a.i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVXki2k8dUd1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2hZZdxVdUd1"
      },
      "source": [
        "#### Q1.a.ii"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKm514b5dUd1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPnhmlgJdUd1"
      },
      "outputs": [],
      "source": [
        "# find average number of products in each group\n",
        "# Calculating the number of data points in each group in the holdout set\n",
        "holdout_group_sizes = holdout.groupby(order_groups.grouper.names).size()\n",
        "\n",
        "# Calculating the average number of data points in each group in the holdout set\n",
        "average_holdout_group_size = holdout_group_sizes.mean()\n",
        "average_holdout_group_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RjxNYQ9dUd2"
      },
      "source": [
        "#### Q1.a.iii"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSCFcKgYdUd2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSW6lJRvdUd2"
      },
      "source": [
        "Investigate minimum number of products in each group in the holdout set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeDC1leqdUd2"
      },
      "outputs": [],
      "source": [
        "minimum_holdout_group_size = holdout_group_sizes.min()\n",
        "minimum_holdout_group_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KO-E5Fx2KIgC"
      },
      "outputs": [],
      "source": [
        "holdout.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93TiZxyFdUd2"
      },
      "outputs": [],
      "source": [
        "#copy coldstart to cold_start and remove coldstart from memory\n",
        "cold_start = coldstart.copy()\n",
        "del coldstart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLzzmCI3KIgC"
      },
      "outputs": [],
      "source": [
        "cold_start.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zauK916NKIgD"
      },
      "outputs": [],
      "source": [
        "holdout.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLKdj1rrKIgD"
      },
      "outputs": [],
      "source": [
        "cold_start.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "3F9yXQN1KIgD"
      },
      "source": [
        "For your **HOLDOUT DATASET** obtained from previous step, for each order, put first 8 products (items) into training set and put the rest into the validation set. If the cart does not have more than 8 items, remove the order from your data pool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vs3crQO3KIgD"
      },
      "outputs": [],
      "source": [
        "order_counts = holdout.groupby('order_id').size().reset_index(name='count')\n",
        "less_than_equal_8_count = order_counts[order_counts['count'] <= 8].shape[0]\n",
        "print('Number of **ORDER_ID** with less than or equal to 8 products: ', less_than_equal_8_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ZtIdu4urKIgD"
      },
      "source": [
        "Remove the order_id that has less than or equal to 8 products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KigaegqaKIgD"
      },
      "outputs": [],
      "source": [
        "filtered_holdout = holdout.groupby('order_id').filter(lambda x: len(x) > 8)\n",
        "filtered_holdout.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "qQOBYe8nKIgE"
      },
      "source": [
        "For each order_id, put first 8 into training set and put the rest into the validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6MTQ0DtdUd3"
      },
      "outputs": [],
      "source": [
        "filtered_holdout = filtered_holdout.astype(int)\n",
        "# Initialize empty dataframes for holdout_train and holdout_valid\n",
        "holdout_train = pd.DataFrame(columns=filtered_holdout.columns)\n",
        "holdout_valid = pd.DataFrame(columns=filtered_holdout.columns)\n",
        "\n",
        "# Group the filtered holdout data by 'order_id'\n",
        "grouped_holdout = filtered_holdout.groupby('order_id')\n",
        "\n",
        "# Iterate over each group and split into holdout_train and holdout_valid\n",
        "for order_id, group in grouped_holdout:\n",
        "    holdout_train = pd.concat([holdout_train, group.head(8).sort_values(by='add_to_cart_order')])\n",
        "    holdout_valid = pd.concat([holdout_valid, group.tail(len(group) - 8).sort_values(by='add_to_cart_order')])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqblXCPodUd3"
      },
      "source": [
        "for each order_id, put them in array for saving and training later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TMzEsAndUd3"
      },
      "outputs": [],
      "source": [
        "train_data = holdout_train.groupby('order_id')['product_id'].apply(list).reset_index()\n",
        "validation_data = holdout_valid.groupby('order_id')['product_id'].apply(list).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMz3W23yKIgF"
      },
      "outputs": [],
      "source": [
        "train_data[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-xN3OeyKIgF"
      },
      "outputs": [],
      "source": [
        "validation_data[-5:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t800BhcFdUd3"
      },
      "outputs": [],
      "source": [
        "train_data = np.array(train_data['product_id'].to_list(), dtype=object)\n",
        "validation_data = np.array(validation_data['product_id'].to_list(), dtype=object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syih3IMidUd7"
      },
      "outputs": [],
      "source": [
        "train_data[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "DqvSSpXtKIgK"
      },
      "source": [
        "#### Q1.b.i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0Lw9LUSdUd7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "f3ZUfrvzKIgL"
      },
      "source": [
        "#### Q1.b.ii"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kU4usgtSdUd7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "4Fh7WVH6KIgL"
      },
      "source": [
        "#### Q1.b.iii"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ghgy30-dUd8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5y-vnEn3dUd8"
      },
      "source": [
        "Save data to file in Data folder for future use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNCUe-KRKIgP"
      },
      "outputs": [],
      "source": [
        "#save train_data and validation_data to file in Data folder as pickle\n",
        "# with open('Data/train_data.pkl', 'wb') as f:\n",
        "#     pickle.dump(train_data, f)\n",
        "#\n",
        "# with open('Data/validation_data.pkl', 'wb') as f:\n",
        "#     pickle.dump(validation_data, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "cDE2kxdlKIgP"
      },
      "source": [
        "load train_data and validation_data from file in Data folder as pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjqiGGXiMPEJ"
      },
      "source": [
        "For Google Collab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcnXd0DGLyOr",
        "outputId": "1a7510ce-8000-4597-d024-49c8a8db6029"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMlIVoHzLtEC"
      },
      "outputs": [],
      "source": [
        "# %cd '/content/drive/MyDrive/RecSys/A3'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-92kHg1I4B5F"
      },
      "source": [
        "Load processed data from file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-25T03:16:09.669980Z",
          "start_time": "2024-06-25T03:16:09.273577Z"
        },
        "id": "m1mGx-gkKIgP"
      },
      "outputs": [],
      "source": [
        "# load train_data and validation_data from file in Data folder as pickle\n",
        "import pickle\n",
        "\n",
        "with open('train_data.pkl', 'rb') as f:\n",
        "    train_data = pickle.load(f)\n",
        "\n",
        "with open('validation_data.pkl', 'rb') as f:\n",
        "    validation_data = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "9TEBDYtLKIgP"
      },
      "source": [
        "## Q2. Train GPT as a sequential recommender system"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "WQI4mAHpKIgP"
      },
      "source": [
        "#### Initialize the hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-25T03:16:44.636671Z",
          "start_time": "2024-06-25T03:16:42.355086Z"
        },
        "id": "O-hmQy58KIgP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 4 # how many independent sequences will we process in parallel?\n",
        "block_size = 4 # what is the maximum context length for predictions?\n",
        "max_iters = 2000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 32\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-25T03:16:51.446933Z",
          "start_time": "2024-06-25T03:16:51.443419Z"
        },
        "id": "nJBjqlJX0cbj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DaGaWRDK528"
      },
      "source": [
        "#### Dataset alignment for Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-25T03:16:57.308251Z",
          "start_time": "2024-06-25T03:16:57.286254Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgwVIcIkKIgQ",
        "outputId": "91ec2b61-b4e8-4638-ed44-df731868ddc1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[11913, 18159, 4461, 21616, 23622, 32433, 28842, 42625],\n",
              " [45221, 12792, 43719, 15483, 21070, 44980, 277, 39979],\n",
              " [45064, 8979, 21955, 14168, 4889, 29487, 14044, 41591],\n",
              " [42244, 31663, 38689, 13176, 21137, 19057, 14901, 18027],\n",
              " [15860, 29628, 28031, 22108, 4126, 31423, 25476, 34284]]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-25T03:19:33.230310Z",
          "start_time": "2024-06-25T03:19:33.165654Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI-PJuSUKIgQ",
        "outputId": "c1270ea3-15fe-4dfe-9711-72aa09b2d068"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25993"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check number of unique product_id's in 'product_id' column of filtered_holdout dataset\n",
        "vocab_size = np.unique(train_data)\n",
        "vocab_size = len(vocab_size)\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-25T03:19:42.607263Z",
          "start_time": "2024-06-25T03:19:42.592265Z"
        },
        "id": "UBweqYlCKIgQ"
      },
      "outputs": [],
      "source": [
        "# now, provide a encoder and decoder. encoder will take in a 2d array and will return a 2d array. each number will be encoded to a unique number corresponding to that number. decoder will take an encoded 2d array and return back the original 2d array.\n",
        "\n",
        "num_mapping = {}\n",
        "rev_mapping = {}\n",
        "\n",
        "def encode(arr):\n",
        "    id_for_unique_number = 1\n",
        "    encoded_arr = []\n",
        "\n",
        "    for row in arr:\n",
        "        encoded_row = []\n",
        "        for num in row:\n",
        "            if num not in num_mapping:\n",
        "                num_mapping[num] = id_for_unique_number\n",
        "                rev_mapping[id_for_unique_number] = num\n",
        "                id_for_unique_number += 1\n",
        "            encoded_row.append(num_mapping[num])\n",
        "        encoded_arr.append(encoded_row)\n",
        "\n",
        "    return encoded_arr\n",
        "\n",
        "\n",
        "def decode(encoded_arr):\n",
        "    decoded_arr = []\n",
        "\n",
        "    for row in encoded_arr:\n",
        "        decoded_row = []\n",
        "        for num in row:\n",
        "            if num == 0:\n",
        "                decoded_row.append(0)\n",
        "            else:\n",
        "                decoded_row.append(rev_mapping[num])\n",
        "        decoded_arr.append(decoded_row)\n",
        "\n",
        "    return decoded_arr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-25T03:19:45.514158Z",
          "start_time": "2024-06-25T03:19:45.500162Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOjKp93BKIgQ",
        "outputId": "c5c2c671-e7fd-48e0-cb55-b705b22c1925"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(46676, 46676)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_data), len(validation_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-25T03:19:54.963907Z",
          "start_time": "2024-06-25T03:19:54.669803Z"
        },
        "id": "aeH711cEKIgR"
      },
      "outputs": [],
      "source": [
        "# now encode train_data and validation_data\n",
        "encoded_train_data = encode(train_data)\n",
        "encoded_validation_data = encode(validation_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-25T03:20:17.327254Z",
          "start_time": "2024-06-25T03:20:17.312115Z"
        },
        "id": "Z9wvc8Q9KIgR"
      },
      "outputs": [],
      "source": [
        "# make sure validation data is same length as train data where block_size is 4.\n",
        "# now validation data is of variable length. so, we need to pad it to make it same length as train data.\n",
        "# we will pad it with 0's\n",
        "def masked_validation_data(val_data, block_size):\n",
        "    # Truncate or pad the validation sequences to match the block_size of training data\n",
        "    aligned_val_data = []\n",
        "\n",
        "    for seq in val_data:\n",
        "        seq_length = len(seq)\n",
        "\n",
        "        if seq_length > block_size:\n",
        "            aligned_val_data.append(seq[:block_size])  # Truncate the sequence\n",
        "        else:\n",
        "            padded_seq = seq + [0] * (block_size - seq_length)  # Pad with 0 token\n",
        "            aligned_val_data.append(padded_seq)\n",
        "\n",
        "    return aligned_val_data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-25T03:20:23.186623Z",
          "start_time": "2024-06-25T03:20:23.105409Z"
        },
        "id": "4xq35DBHKIgR"
      },
      "outputs": [],
      "source": [
        "# convert the train_data and validation_data to tensors\n",
        "train_data_tensor = torch.tensor(encoded_train_data)\n",
        "validation_data_tensor = torch.tensor(masked_validation_data(encoded_validation_data, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-25T03:20:26.664852Z",
          "start_time": "2024-06-25T03:20:26.651902Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16OHJ1ENKIgR",
        "outputId": "28cea868-4da4-4cb0-df65-ad20f8823e53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([46676, 8]), torch.Size([46676, 8]))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check the shape of train_data_tensor and validation_data_tensor\n",
        "train_data_tensor.shape, validation_data_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-25T03:20:48.425193Z",
          "start_time": "2024-06-25T03:20:48.410191Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWVyv5MCP6EB",
        "outputId": "4656ed56-250a-4b8a-b5c7-9b82c8a14393"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8],\n",
              "        [ 9, 10, 11, 12, 13, 14, 15, 16]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data_tensor[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIc0TptCM6F4"
      },
      "source": [
        "#### Batch Production"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-25T03:21:56.120286Z",
          "start_time": "2024-06-25T03:21:56.102291Z"
        },
        "id": "CFZhNC26pwf2"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def get_batch(split):\n",
        "  data = train_data_tensor if split == 'train' else validation_data_tensor\n",
        "  shape = data.shape\n",
        "\n",
        "  ix = random.sample(range(shape[0]), batch_size)  # Generate 4 random integers\n",
        "  jx = random.sample(range(shape[1] - block_size), batch_size)\n",
        "\n",
        "  x = torch.empty(0, block_size, dtype=torch.long)\n",
        "  y = torch.empty(0, block_size, dtype=torch.long)\n",
        "\n",
        "  for i in range(batch_size):\n",
        "    x_temp = data[ix[i]:ix[i]+1, jx[i]:jx[i]+block_size]\n",
        "    y_temp = data[ix[i]:ix[i]+1, jx[i]+1: jx[i]+1+block_size]\n",
        "\n",
        "    x = torch.cat((x, x_temp), dim=0)\n",
        "    y = torch.cat((y, y_temp), dim=0)\n",
        "\n",
        "  x, y = x.to(device), y.to(device)\n",
        "\n",
        "  return x, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-25T03:21:59.082318Z",
          "start_time": "2024-06-25T03:21:58.881587Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qbgqyOHPRwT",
        "outputId": "0c41c4d4-7d42-4d2a-92e3-78be74cd0e00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[  409, 12331,  5869,    41],\n",
              "         [  808,  5877,   480, 17435],\n",
              "         [ 1618,  3349,  9102,    53],\n",
              "         [ 3418,    81,   575,  1420]], device='cuda:0'),\n",
              " tensor([[12331,  5869,    41,   513],\n",
              "         [ 5877,   480, 17435,  7551],\n",
              "         [ 3349,  9102,    53,   447],\n",
              "         [   81,   575,  1420,  2078]], device='cuda:0'))"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_batch(\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-25T03:22:17.723436Z",
          "start_time": "2024-06-25T03:22:17.694435Z"
        },
        "id": "_34EOppOyNIH"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "# super simple bigram model\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        tok_emb = self.token_embedding_table(idx.long())  # Convert idx to torch.long\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
        "        x = tok_emb + pos_emb\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B * T, C)\n",
        "            targets = targets.view(B * T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, loss = self(idx_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-25T03:22:20.294768Z",
          "start_time": "2024-06-25T03:22:20.280771Z"
        },
        "id": "-l6yyKV9sR-4"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzN1FKAiARjQ"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFrQqqfpyady",
        "outputId": "ab1081cb-2f62-4b94-db9d-e5143ae0e6cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.740169 M parameters\n",
            "step 0: train loss 10.3236, val loss 10.4750\n",
            "step 19: train loss 10.2479, val loss 10.3671\n"
          ]
        }
      ],
      "source": [
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "train_losses = []\n",
        "print_interval = 200\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "        train_losses.append(losses['train'])\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aOtQP-7mAmD"
      },
      "source": [
        "#### Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcOdrwl0mP6f"
      },
      "outputs": [],
      "source": [
        "path = 'base_model.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiblXi6bl_RA"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "torch.save(m.state_dict(), path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6VW8yAHmJLh"
      },
      "source": [
        "#### Load the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEJi22BcmGGI",
        "outputId": "3fbce676-6eb9-44bf-b3a0-e81f38a93494"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BigramLanguageModel(\n",
              "  (token_embedding_table): Embedding(25993, 32)\n",
              "  (position_embedding_table): Embedding(4, 32)\n",
              "  (blocks): Sequential(\n",
              "    (0): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-3): 4 x Head(\n",
              "            (key): Linear(in_features=32, out_features=8, bias=False)\n",
              "            (query): Linear(in_features=32, out_features=8, bias=False)\n",
              "            (value): Linear(in_features=32, out_features=8, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ffwd): FeedFoward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (1): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-3): 4 x Head(\n",
              "            (key): Linear(in_features=32, out_features=8, bias=False)\n",
              "            (query): Linear(in_features=32, out_features=8, bias=False)\n",
              "            (value): Linear(in_features=32, out_features=8, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ffwd): FeedFoward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (2): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-3): 4 x Head(\n",
              "            (key): Linear(in_features=32, out_features=8, bias=False)\n",
              "            (query): Linear(in_features=32, out_features=8, bias=False)\n",
              "            (value): Linear(in_features=32, out_features=8, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ffwd): FeedFoward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (3): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-3): 4 x Head(\n",
              "            (key): Linear(in_features=32, out_features=8, bias=False)\n",
              "            (query): Linear(in_features=32, out_features=8, bias=False)\n",
              "            (value): Linear(in_features=32, out_features=8, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ffwd): FeedFoward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "  (lm_head): Linear(in_features=32, out_features=25993, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the model\n",
        "model = BigramLanguageModel()\n",
        "model.load_state_dict(torch.load(path))\n",
        "m = model.to(device)\n",
        "m.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvJs2Cs5Ah9v"
      },
      "source": [
        "##### Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p1XQnseE4aT"
      },
      "source": [
        "Evaluation Metrics for Sequential RecSys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KziZaKo8GkfR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def precision_at_k(true_list, predicted_list, k):\n",
        "    true_positive = len(set(true_list[:k]) & set(predicted_list[:k]))\n",
        "    if k == 0:\n",
        "        return 0\n",
        "    return true_positive / k\n",
        "\n",
        "def recall_at_k(true_list, predicted_list, k):\n",
        "    true_positive = len(set(true_list[:k]) & set(predicted_list[:k]))\n",
        "    actual_positive = len(set(true_list))\n",
        "    if actual_positive == 0:\n",
        "        return 0\n",
        "    return true_positive / actual_positive\n",
        "\n",
        "def ndcg_at_k(true_list, predicted_list, k):\n",
        "    relevance = [1 if item in true_list else 0 for item in predicted_list[:k]]\n",
        "    if np.sum(relevance) == 0:\n",
        "        return 0\n",
        "\n",
        "    dcg = relevance[0]\n",
        "    for i in range(1, len(relevance)):\n",
        "        dcg += relevance[i] / np.log2(i + 1)\n",
        "\n",
        "    ideal_relevance = sorted(relevance, reverse=True)\n",
        "\n",
        "    idcg = ideal_relevance[0]\n",
        "    for i in range(1, len(ideal_relevance)):\n",
        "        idcg += ideal_relevance[i] / np.log2(i + 1)\n",
        "\n",
        "    return dcg / idcg\n",
        "\n",
        "def evaluate_performance(true_lists, predicted_lists):\n",
        "    assert len(true_lists) == len(predicted_lists), \"Number of lists must be the same\"\n",
        "\n",
        "    precision = []\n",
        "    recall = []\n",
        "    ndcg = []\n",
        "    k_values = [1, 3, 5]\n",
        "\n",
        "    for true_list, predicted_list in zip(true_lists, predicted_lists):\n",
        "        for k in k_values:\n",
        "            precision_k = precision_at_k(true_list, predicted_list, k)\n",
        "            recall_k = recall_at_k(true_list, predicted_list, k)\n",
        "            ndcg_k = ndcg_at_k(true_list, predicted_list, k)\n",
        "\n",
        "            precision.append(precision_k)\n",
        "            recall.append(recall_k)\n",
        "            ndcg.append(ndcg_k)\n",
        "\n",
        "    avg_precision = np.mean(precision)\n",
        "    avg_recall = np.mean(recall)\n",
        "    avg_ndcg = np.mean(ndcg)\n",
        "\n",
        "    return avg_precision, avg_recall, avg_ndcg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJUxiOzFGyJd"
      },
      "outputs": [],
      "source": [
        "def print_Performance_2(true_val, pred_val):\n",
        "  precision, recall, ndcg = evaluate_performance(true_val, pred_val)\n",
        "\n",
        "  print(\"Precision@k:\", precision)\n",
        "  print(\"Recall@k:\", recall)\n",
        "  print(\"nDCG@k:\", ndcg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxFashYLGAh-"
      },
      "source": [
        "### Q3.a.i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nd6hkI60Hn7L"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def holdout_predictions_data():\n",
        "  list_true = []\n",
        "  list_predict = []\n",
        "  prediction_count = 0\n",
        "  MAX_PREDICTIONS = 4\n",
        "\n",
        "  for i in tqdm(range(len(train_data_tensor) - 1, -1, -1), total=MAX_PREDICTIONS):\n",
        "      train_row = train_data_tensor[i]\n",
        "      validation_row = validation_data_tensor[i].tolist()\n",
        "      validation_row = [i for i in validation_row if i != 0]\n",
        "\n",
        "      if len(validation_row) < 5:\n",
        "          continue\n",
        "\n",
        "      ### update your code here\n",
        "      cart_seq = train_row[\n",
        "      ]\n",
        "      ### update your code here\n",
        "\n",
        "      #now predict from the model\n",
        "      context = cart_seq.unsqueeze(0).to(device)\n",
        "\n",
        "      predict = m.generate(context, max_new_tokens=len(validation_row))[0].tolist()\n",
        "\n",
        "      # copy only the prediction from the sequence\n",
        "      predict = predict[-len(validation_row):]\n",
        "\n",
        "      #keep tab of true and predicted value for performance evaluation\n",
        "      list_true.append(validation_row)\n",
        "      list_predict.append(predict)\n",
        "\n",
        "      prediction_count += 1\n",
        "\n",
        "      if prediction_count == MAX_PREDICTIONS:\n",
        "          break\n",
        "\n",
        "  return list_true, list_predict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoQEx5A7HTD8",
        "outputId": "b0a2c6c0-1046-4b56-f2b9-595153005936"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1999/2000 [03:01<00:00, 10.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performance on Holdout Dataset: \n",
            "Precision@k: 0.00012222222222222224\n",
            "Recall@k: 6.25e-05\n",
            "nDCG@k: 0.0012539531690476384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "list_true, list_predict = holdout_predictions_data()\n",
        "\n",
        "print('Performance on Holdout Dataset: ')\n",
        "print_Performance_2(list_true, list_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-WWNavlI8Gr"
      },
      "source": [
        "### Q3.b.ii Performance with **cold_start** dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3coiTTQlK3y0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI0xvwx7iC0W"
      },
      "source": [
        "### Q3.C.i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13S-XRLvdUeC"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTvqqlbTjiQz"
      },
      "source": [
        "### Q3.C.ii\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blU3X28bdUeD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
